{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLGKRYkof4m606Xk5BLDPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snow-white2024/AIFFEL_quest_cr/blob/master/250408_%EC%8B%A4%EC%A0%9C%EC%9D%8C%EC%84%B1%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A6%9D%EA%B0%95%ED%9B%84%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWurKpD5RQlD",
        "outputId": "4863f965-a44a-43fe-a582-225a4fb31d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/dataset'"
      ],
      "metadata": {
        "id": "bpkqOtBRRXCr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def extract_features(file_path):\n",
        "    # 오디오 파일 로드\n",
        "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # MFCC 특징 추출\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "\n",
        "    # MFCC의 평균값을 특징으로 사용\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "\n",
        "    return mfcc_mean\n",
        "\n",
        "def load_data(dataset_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    stable_path = os.path.join(dataset_path, 'stable')  # 안정된 상태 폴더\n",
        "    for filename in os.listdir(stable_path):\n",
        "        if filename.endswith('.wav'):\n",
        "            file_path = os.path.join(stable_path, filename)\n",
        "            feature = extract_features(file_path)\n",
        "            features.append(feature)\n",
        "            labels.append(0)  # 안정된 상태 레이블은 0\n",
        "\n",
        "    running_path = os.path.join(dataset_path, 'running')  # 중고강도 상태 폴더\n",
        "    for filename in os.listdir(running_path):\n",
        "        if filename.endswith('.wav'):\n",
        "            file_path = os.path.join(running_path, filename)\n",
        "            feature = extract_features(file_path)\n",
        "            features.append(feature)\n",
        "            labels.append(1)  # 중고강도 상태 레이블은 1\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# 구글 드라이브의 경로로 데이터 로드\n",
        "dataset_path = '/content/drive/MyDrive/dataset'  # 경로를 실제 위치에 맞게 변경하세요\n",
        "X, y = load_data(dataset_path)\n"
      ],
      "metadata": {
        "id": "f6ptyhAaSExw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# 피치 변형 함수\n",
        "def pitch_shift(audio, sample_rate, n_steps):\n",
        "    return librosa.effects.pitch_shift(audio, sample_rate, n_steps=n_steps)\n",
        "\n",
        "# 시간 신속도 조정 함수\n",
        "def time_stretch(audio, rate):\n",
        "    return librosa.effects.time_stretch(audio, rate)\n",
        "\n",
        "# 데이터 증강 함수\n",
        "def augment_data(audio, sample_rate):\n",
        "    augmented_data = []\n",
        "\n",
        "    # 원본 데이터\n",
        "    augmented_data.append(audio)\n",
        "\n",
        "    # 피치 변형\n",
        "    augmented_data.append(pitch_shift(audio, sample_rate, n_steps=2))  # +2피치\n",
        "    augmented_data.append(pitch_shift(audio, sample_rate, n_steps=-2))  # -2피치\n",
        "\n",
        "    # 시간 신속도 조정\n",
        "    augmented_data.append(time_stretch(audio, rate=1.2))  # 느리게\n",
        "    augmented_data.append(time_stretch(audio, rate=0.8))  # 빠르게\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "# 예시: 오디오 파일을 로드하고 증강 적용\n",
        "def load_and_augment(file_path):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "    augmented_audios = augment_data(audio, sample_rate)\n",
        "    return augmented_audios\n"
      ],
      "metadata": {
        "id": "jV335M9jSvrJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 레이블을 one-hot 인코딩\n",
        "y = to_categorical(y, num_classes=2)\n",
        "\n",
        "# 데이터셋을 학습용과 테스트용으로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "JvSTRVb4S4Tc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "# LSTM 모델 구축\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))  # 두 가지 클래스를 예측\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y24K-_FQTK6Z",
        "outputId": "7928fd95-a288-41cc-c48c-45bdfea73e0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 차원 맞추기 (LSTM에 맞게 입력 형태 변환)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n"
      ],
      "metadata": {
        "id": "roWb1uBATQpC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWNn8FuFTVtY",
        "outputId": "fae2c26a-0fd2-442b-aa5d-e2e7afd829e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5000 - loss: 0.7118 - val_accuracy: 1.0000 - val_loss: 0.6611\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.3333 - loss: 0.7025 - val_accuracy: 1.0000 - val_loss: 0.6364\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8333 - loss: 0.6622 - val_accuracy: 1.0000 - val_loss: 0.6118\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.6667 - loss: 0.6217 - val_accuracy: 1.0000 - val_loss: 0.5853\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8333 - loss: 0.5733 - val_accuracy: 1.0000 - val_loss: 0.5616\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.5172 - val_accuracy: 1.0000 - val_loss: 0.5359\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.5563 - val_accuracy: 1.0000 - val_loss: 0.5080\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6667 - loss: 0.6275 - val_accuracy: 1.0000 - val_loss: 0.4772\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8333 - loss: 0.5002 - val_accuracy: 1.0000 - val_loss: 0.4426\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8333 - loss: 0.5289 - val_accuracy: 1.0000 - val_loss: 0.4042\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.4109 - val_accuracy: 1.0000 - val_loss: 0.3624\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8333 - loss: 0.4248 - val_accuracy: 1.0000 - val_loss: 0.3219\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.3906 - val_accuracy: 1.0000 - val_loss: 0.2859\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.3622 - val_accuracy: 1.0000 - val_loss: 0.2456\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.1932 - val_accuracy: 1.0000 - val_loss: 0.2091\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.2180 - val_accuracy: 1.0000 - val_loss: 0.1755\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.1508 - val_accuracy: 1.0000 - val_loss: 0.1393\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 0.1178 - val_accuracy: 1.0000 - val_loss: 0.1029\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.1506 - val_accuracy: 1.0000 - val_loss: 0.0687\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0887 - val_accuracy: 1.0000 - val_loss: 0.0461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78130e50c750>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz1lmoHdTdbr",
        "outputId": "fbd66db6-153c-4b5f-8b0e-2a73678e3bdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0461\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}